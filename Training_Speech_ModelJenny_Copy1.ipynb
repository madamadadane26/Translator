{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d764152",
      "metadata": {
        "id": "9d764152",
        "outputId": "77b45f47-4cee-4927-f9e4-1a27ef037a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\jenny\\anaconda3\\lib\\site-packages (2.10.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\jenny\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (22.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jenny\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.6.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: librosa in c:\\users\\jenny\\anaconda3\\lib\\site-packages (0.10.0.post2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (1.10.0)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\jenny\\appdata\\roaming\\python\\python310\\site-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (1.2.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\jenny\\appdata\\roaming\\python\\python310\\site-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\jenny\\appdata\\roaming\\python\\python310\\site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jenny\\appdata\\roaming\\python\\python310\\site-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (22.0)\n",
            "Requirement already satisfied: requests in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (2.28.1)\n",
            "Requirement already satisfied: appdirs in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jenny\\anaconda3\\lib\\site-packages (from requests->pooch<1.7,>=1.0->librosa) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d483de",
      "metadata": {
        "id": "e0d483de",
        "outputId": "fc1a2fcb-1a9e-4189-d234-b22130d1e552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RecursionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0808a2d5faac>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscriptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of X:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-0808a2d5faac>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, sample_rate, n_mels, max_len)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "... last 1 frames repeated, from the frame below ...\n",
            "\u001b[0;32m<ipython-input-1-0808a2d5faac>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, sample_rate, n_mels, max_len)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, BatchNormalization, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import TimeDistributed, LSTM, Bidirectional, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.backend import ctc_batch_cost\n",
        "import re\n",
        "\n",
        "\n",
        "data_dir = 'C:\\\\Users\\\\jenny\\\\Notebooks\\\\LibriSpeech\\\\train-clean-100'\n",
        "train_path = os.path.join(data_dir, 'train-clean-100')\n",
        "\n",
        "def extract_features(file_path, sample_rate=16000, n_mels=128):\n",
        "    audio, _ = librosa.load(file_path, sr=sample_rate, res_type='kaiser_fast', dtype=np.float32)\n",
        "    print(type(audio))  # Debugging: print the type of audio\n",
        "    mfccs = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
        "    mfccs = librosa.power_to_db(mfccs).T\n",
        "    return mfccs\n",
        "\n",
        "def load_data(path, sample_rate=16000, n_mels=128, max_len=300):\n",
        "    X, y, transcriptions = load_data(train_path)\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        print(f\"Processing directory: {root}\")\n",
        "        for file in files:\n",
        "            if file.endswith('.flac'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    label = int(file.split('-')[0])\n",
        "                    transcription_file = os.path.join(root, file.replace('.flac', '.txt'))\n",
        "                    with open(transcription_file, 'r') as f:\n",
        "                        transcription = f.read().strip()\n",
        "                    features = extract_features(file_path, sample_rate, n_mels)\n",
        "                    if features.shape[0] < max_len:\n",
        "                        padding = np.zeros((max_len - features.shape[0], n_mels))\n",
        "                        features = np.vstack((features, padding))\n",
        "                    else:\n",
        "                        features = features[:max_len, :]\n",
        "                    X.append(features)\n",
        "                    y.append(label)\n",
        "                    transcriptions.append(transcription)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file_path}: {e}\")\n",
        "                    transcriptions.append(None)\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    transcriptions = np.array(transcriptions)\n",
        "    X = X[..., np.newaxis]\n",
        "    y = to_categorical(y)\n",
        "    return X, y, transcriptions\n",
        "\n",
        "X, y, transcriptions = load_data(train_path)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "print(\"Shape of transcriptions:\", transcriptions.shape)\n",
        "\n",
        "\n",
        "y = to_categorical(y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_val = X_val[..., np.newaxis]\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = TimeDistributed(Flatten())(x)\n",
        "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_classes)(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    outputs = Lambda(lambda x: tf.keras.backend.ctc_decode(x, input_length=tf.ones(tf.shape(x)[0])*tf.shape(x)[1], greedy=True)[0][0])(outputs)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "num_classes = y_train.shape[1]\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer=Adam(), loss=ctc_batch_cost)\n",
        "model.summary()\n",
        "\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate the model\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f'Train accuracy: {train_acc * 100:.2f}%, Validation accuracy: {val_acc * 100:.2f}%')\n",
        "\n",
        "# Plot the training history\n",
        "plot_history(history)\n",
        "\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = os.path.join(os.getcwd(), 'trained_model1.h5')\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to: {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ba6c84",
      "metadata": {
        "id": "a8ba6c84"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520197a6",
      "metadata": {
        "id": "520197a6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}